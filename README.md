# Spline-VGP-Projekt

Untersuchung einer **Spline-basierten Sigmoid-Aktivierungsfunktion** zur AbschwÃ¤chung des *Vanishing-Gradient-Problems (VGP)* in tiefen Feedforward-Netzen. Neben der eigenen Spline-Aktivierung werden **ReLU** und **Sigmoid** als Baselines verglichen.

> TL;DR: Kubische (Hermite-)Splines approximieren die Sigmoidkurve im Bereich `[-2, 2]`. AuÃŸerhalb lÃ¤uft die Funktion linear aus â€“ mit steilerer/konstanterer Ableitung, um VGP zu mildern.

---

## ğŸ”¬ Idee & Hypothese

- **Warum Spline?** Sigmoid sÃ¤ttigt fÃ¼r groÃŸe |x| â†’ Gradienten verschwinden. Die Spline-Variante verhÃ¤lt sich *sigmoid-Ã¤hnlich* nahe 0, lÃ¤uft aber **linear** auÃŸerhalb `[-2, 2]`.  
- **Hypothese:** stabilere Gradienten in tiefen MLPs â†’ weniger VGP-Effekte (sichtbar in Gradienten-Heatmaps), ohne die Robustheit von ReLU vollstÃ¤ndig zu verlieren.

---

## ğŸ§© Aktivierungsfunktionen

- **ReLU**  
- **Sigmoid**
- **Spline (eigene Variante)** â€“ sigmoid-nah im Kernbereich, linear auÃŸerhalb.

Die Spline ist Ã¼ber kubische Hermite-Splines implementiert, Parameter:
- `n`: Anzahl der Segmente innerhalb `[-x_limit, x_limit]` (Standard: 2)  
- `x_limit`: Spline-Kernbereich (Standard: 2)

Illustration (Sigmoid vs. Spline sowie Ableitungen):

![sigmoid_vs_spline.png](spline_vs_sigmoid.png)

---

## ğŸ“¦ DatensÃ¤tze

- **FashionMNIST** â€“ 60 000 Graustufenbilder 28Ã—28 (10 Klassen)  
- **CIFAR-10** â€“ 50 000 Farbbilder 32Ã—32 (10 Klassen)  
- **Tiny ImageNet-200** â€“ 100 0000 Farbbilder 64x64 (200 Klassen)

FÃ¼r FashionMNIST/CIFAR-10 dient das Testset als **Validation** (keine finale Testphase, Fokus auf GradientenverlÃ¤ufe).

---

## ğŸ› ï¸ Setup

Voraussetzungen:
- Python **3.11** (empfohlen)
- (Optional) NVIDIA-GPU mit CUDA 12.x

```bash
python -m venv venv
source venv/bin/activate     # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

## Daten vorbereiten

FashionMNIST und CIFAR-10 werden automatisch geladen.
**Tiny ImageNet-200** bitte manuell laden, z. B.:

```bash
wget http://cs231n.stanford.edu/tiny-imagenet-200.zip
unzip tiny-imagenet-200.zip -d data/
```

Struktur (relevant):

```text
data/
â””â”€â”€ tiny-imagenet-200/
    â”œâ”€â”€ train/
    â””â”€â”€ val/
        â”œâ”€â”€ images/
        â””â”€â”€ val_annotations.txt
```

---

## âš™ï¸ Konfigurationen

Experimente werden Ã¼ber YAML-Dateien definiert (Beispiel):

```yaml
# experiments/configs/spline_cifar10.yaml
experiment_name: spline_cifar10
seed: 42

dataset: cifar10          # fashionmnist | cifar10 | tiny_imagenet
batch_size: 1024
hidden_dim: 512
depth: 16                  # Anzahl versteckter Schichten (MLP)
activation: spline        # relu | sigmoid | spline
learning_rate: 1.0e-3
epochs: 250

log_dir: logs/spline_cifar10
```

---

## ğŸš€ Einzelexperiment starten

```bash
python experiments/run_experiment.py --config experiments/configs/spline_cifar10.yaml
```
- Logs: `logs/<experiment_name>/`
- Metriken: `metrics.csv`
- Trainingslog: `training.log`

LÃ¤uft auf GPU, falls verfÃ¼gbar. Logs/Outputs:

- Metriken (pro Epoche/Parameter): logs/<experiment_name>/metrics.csv
- Konsolen-Log des Trainings: logs/<experiment_name>/training.log

---

## ğŸ” Alle Experimente ausfÃ¼hren

Alle YAMLs in experiments/configs/ werden nacheinander trainiert und anschlieÃŸend automatisch geplottet:

```bash
python run_all_experiments.py
```

Smoke-Runs (klein & schnell, ideal fÃ¼r Checks):

```bash
python run_all_experiments.py --smoke
# erzeugt zusammengehÃ¶rige Smoke-Plots
```

---

## ğŸ“Š Auswertung & Plots

Alle vorhandenen CSV-Logs plotten:

```bash
python results/plots/plot_all.py
# oder smoke-Logs
python results/plots/plot_all.py --smoke
```

Erzeugt:

- **Gradient-Heatmaps** (log10 von mean-|gradient| und â€–gradâ€–)
- **Loss/Accuracy-VerlÃ¤ufe** (Train/Val, log10-Loss & Top-1-Accuracy)
- **Trainingszeiten**-Balkendiagramm

Ablage:
```text
results/
â””â”€â”€ plots/
    â”œâ”€â”€ gradient_heatmaps/
    â”œâ”€â”€ loss_acc/
    â””â”€â”€ train_times.png
```

---

## ğŸ§± Architektur (kurz)

- **Modell:** tiefes MLP (FNN), Bilder werden flach eingegeben.
- **Initialisierung:** Xavier-Uniform (Sigmoid/Spline), Kaiming-Uniform (ReLU).
- **Optimierer/Loss:** Adam + CrossEntropyLoss.
- **Logging:** pro Epoche Mittelwerte von mean-|Grad| und Grad-Norm je Parameter, inkl. Train/Val-Loss & -Accuracy.

---

## ğŸ§ª Reproduzierbarkeit & Performance

- Feste Seeds fÃ¼r Python/NumPy/PyTorch; deterministische CUDNN-Einstellungen.
- TF32 und hohe MatMul-PrÃ¤zision sind aktiviert (Ampere+), um Training zu beschleunigen.

---

## ğŸ“‚ Projektstruktur

```text
spline-vgp-project/
â”œâ”€â”€ data/
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ configs/            # YAML-Experimente (+ smoke/)
â”‚   â””â”€â”€ run_experiment.py   # Einzellauf
â”œâ”€â”€ logs/                   # Metriken/Logs pro Experiment
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ activations.py      # Stellt Aktivierungen bereit
â”‚   â”œâ”€â”€ feedforward.py      # FFN-Implementierung (MLP)
â”‚   â””â”€â”€ sigmoid_spline_activation.py  # Spline-basierte Sigmoid
â”œâ”€â”€ results/
â”‚   â””â”€â”€ plots/              # Heatmaps, Loss/Acc, Zeiten
â”‚       â””â”€â”€ plot_all.py     # Auswertung & Plots (+ --smoke)
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ trainer.py          # Training/Eval + Gradienten-Logging
â”‚   â””â”€â”€ utils.py            # Dataloader, Seeds, Init
â”œâ”€â”€ run_all_experiments.py   # Batch-Runner (+ --smoke)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## â• Erweiterbarkeit

**Neue Aktivierung hinzufÃ¼gen**

1. Implementierung als ``nn.Module`` (analog zur Spline).
2. In ``models/activations.py`` in ``get_activation(...)`` registrieren.
3. In YAML ``activation: <name>`` setzen.

**Neues Dataset**

1. Dataloader/Transforms in ``training/utils.py`` ergÃ¤nzen.
2. Input/Output-Dim korrekt setzen.
3. YAML anpassen.
