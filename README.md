# Spline-VGP-Projekt

Dieses Projekt untersucht eine splinebasierte Variante der Sigmoid-Aktivierungsfunktion, um das **Vanishing-Gradient-Problem (VGP)** zu verringern.

---

## ğŸ“ˆ Aktivierungen

Um die neue Spline-Aktivierung zu bewerten, vergleiche ich ihre Ergebnisse mit denen der ReLU- und der klassischen Sigmoidfunktion. Sigmoid ist in tiefen Netzen besonders anfÃ¤llig fÃ¼r das VGP, wÃ¤hrend ReLU als robuster Industriestandard gilt.

Aktivierungen:

- ReLU
- Sigmoid
- Spline (eigene Variante der Sigmoidfunktion)

> Im Folgenden wird die splinebasierte Aktivierungsfunktion der Einfachheit halber nur **Spline** genannt.

### ğŸ“ˆ Eigene Spline-Aktivierung

Die Funktion basiert auf der Sigmoidfunktion. Ein kubischer Spline approximiert den Bereich `[-2, 2]`; auÃŸerhalb verlÃ¤uft die Funktion linear weiter.

![sigmoid_vs_spline.png](spline_vs_sigmoid.png)

Wie im rechten Plot zu sehen, bleibt die Ableitung auÃŸerhalb des Bereichs `[-2, 2]` steiler und sollte damit dem VGP entgegenwirken.

---

## ğŸ“¦ Datasets

Die folgenden drei Datasets decken unterschiedliche Schwierigkeitsgrade ab und liefern damit diversere Ergebnisse.

1. **FashionMNIST** â€“ 70.000 Graustufenbilder (28Ã—28) mit 10 Klassen.
2. **CIFAR10** â€“ 60.000 Farbbilder (32Ã—32) mit 10 Klassen.
3. **TinyImageNetâ€‘200** â€“ 200 Klassen mit insgesamt 120.000 Farbbildern (64Ã—64; Train/Val/Test 100k/10k/10k).

FÃ¼r FashionMNIST und CIFAR10 dient das jeweilige Testset als Validation-Set. Eine abschlieÃŸende Testphase entfÃ¤llt, da der Fokus auf den GradientenverlÃ¤ufen wÃ¤hrend des Trainings liegt. Verlust und Genauigkeit dienen lediglich als zusÃ¤tzliche Indikatoren.

---

## ğŸ› ï¸ Setup

Projekt Setup:

```sh
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

FÃ¼r CUDAÂ 12.6 UnterstÃ¼tzung:

```sh
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
```

TinyImageNetâ€‘200 herunterladen von [Kaggle](https://www.kaggle.com/datasets/nikhilshingadiya/tinyimagenet200) oder via:

```sh
wget http://cs231n.stanford.edu/tiny-imagenet-200.zip
```

AnschlieÃŸend den entpackten Ordner unter `data/` ablegen.

> Alle anderen Datasets werden beim ersten AusfÃ¼hren automatisch heruntergeladen und gespeichert.

---

## ğŸš€ Einzelnes Experiment starten

```sh
python experiments/run_experiment.py --config experiments/configs/spline_cifar10.yaml
```
- Logs: `logs/<experiment_name>/`
- Metriken: `metrics.csv`
- Trainingslog: `training.log`

---

## ğŸ“Š Alle vorhandenen CSV-Logs plotten

```sh
python results/plots/plot_all.py
```
- durchsucht alle Log-Unterverzeichnisse nach `metrics.csv`
- erstellt Gradient-Heatmaps sowie Loss- und Accuracy-VerlÃ¤ufe
- speichert Plots unter `results/plots/gradient_heatmaps/` bzw. `results/plots/loss_acc/`

---

## ğŸ” Alle Experimente automatisch ausfÃ¼hren

```sh
python run_all_experiments.py
```
- iteriert Ã¼ber alle `.yaml`-Dateien in `experiments/configs/`
- fÃ¼hrt Training, Logging und Plotting durch

---

## ğŸ“‚ Projektstruktur

```sh
spline-vgp-project/
â”œâ”€â”€ data/
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ configs/            # YAML-Experimente
â”‚   â””â”€â”€ run_experiment.py   # Einzellauf
â”œâ”€â”€ logs/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ activations.py      # Stellt Aktivierungen bereit
â”‚   â”œâ”€â”€ feedforward.py      # FFN-Implementierung
â”‚   â””â”€â”€ sigmoid_spline_activation.py  # Spline-basierte Sigmoid-Implementierung
â”œâ”€â”€ results/
â”‚   â””â”€â”€ plots/
â”‚       â”œâ”€â”€ gradient_heatmaps         # Heatmaps der Gradienten
â”‚       â””â”€â”€ loss_acc                  # Loss- und Accuracy-VerlÃ¤ufe
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ trainer.py          # Training und Validierung
â”‚   â””â”€â”€ utils.py            # Dataloader, Seed-Setting, Gewichtsinitialisierung
â”œâ”€â”€ run_all_experiments.py  # Automatisierter Durchlauf aller Experimente
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```
