# Spline-VGP-Project

In diesem Projekt will ich versuchen, mit Hilfe einer *splinebasierten Abwandlung der Sigmoidfunktion*, das **Vanishing-Gradient-Problem (VGP)** zu vermindern.

---

## ğŸ“ˆ Aktivierungen

Um die neue ***splinebasierte Sigmoidfunktion*** auf ihre Nutzen zu Ã¼berprÃ¼fen, vergleiche ich sÃ¤mtliche Ergebnisse mit denen der ReLU- und Sigmoidfunktion. Die ***Sigmoidfunktion*** ist bekannt dafÃ¼r in tiefen Netzen mit vielen Schichten besonders anfÃ¤llig fÃ¼r das VGP zu sein. Die ***ReLU-Aktivierungsfunktion*** hingegen soll im Vergleich als Wegweiser gelten, da sie vom Design her nicht anfÃ¤llig fÃ¼r das VGP ist und auÃŸerdem als Industriestandard fÃ¼r die meisten Neuronalen Netze gilt.

Aktivierungen:

- ReLU

- Sigmoid

- Spline (eigene splinebasierte Abwandlung der Sigmoidfunktion)

> Die ***splinebasierte Abwandlung der Sigmoid-Aktivierungsfunktion*** wird in jeglichen folgenden Abbildungen und ErwÃ¤hnungen, der Einfachheit halber, nur als ***spline*** bezeichnet.

### ğŸ“ˆ Eigene Spline Aktivierungs

Meine eigene splinebasierte Aktivierungsfunktion basiert auf der *Sigmoidfunktion* und modifiziert diese. Unter der verwendung eines *kubischen Splines* wird die Sigmoidfunktion im Bereich `[-2, 2]` nachgebildet und verlÃ¤uft auÃŸerhalb dieser grenzen linear weiter.

![sigmoid_vs_spline.png](/spline_vs_sigmoid.png)

Wie auf dem rechten Plot der Abbildung zu sehen ist, verlÃ¤uft die Ableitung der Splinevariante nicht mehr flach auÃŸerhalb von `[-2, 2]`, was in der Theorie bereits dem VGP entgegenwirken sollte.

---

## ğŸ“¦ Datasets

Ich habe mich fÃ¼r die folgenden drei Datasets entschieden, da sie das Netz unterschiedlich stark fordern und somit mÃ¶glichst diversifizierte Ergebnisse liefern. ***FashionMnist*** ist hier das simpelste Dataset. Es beruht auf 70.000 (train/test 60.000/10.000) 28x28 Bildern, die nur in GrautÃ¶nen abgebildet sind. Jedes Bild wird hier einem von 10 Bezeichnungen (Klassen) zugeordnet, was in diesem Fall Zalando-Artikel sind. ***Cifar10*** soll hier als erste Steigerung in der Schwierigkeit gelten. Es besteht aus 60.000 (train/test 50.000/10.000) 32x32 farbigen Bildern, die ebenfalls je einer von 10 Klassen zugeordnet werden. Als hÃ¶chste Steigerung fÃ¼r dieses Projekt soll das Dataset ***TinyImagenet-200*** als Skalierungstest dienen. Mit 100.000 (train/test/val 100.000/10.000/10.000) 64x64 Bildern in Farbe und 200 Klassen ist es das grÃ¶ÃŸte und komplexeste Dataset im Vergleich. Wichtig ist zu erwÃ¤hnen, dass ich bei den Datasets *FashionMnist* und *Cifar10* das vorgeschriebene Test-Dataset als Validation-Dataset zweckentfremdet habe. Das hat den Grund, dass ich fÃ¼r diesen Versuchsaufbau auf eine Testphase nach dem Trainieren der Modelle verzichtet habe, da fÃ¼r mich die *GradientenverÃ¤nderungen* wÃ¤hrend des Trainings im Vordergrund standen. *Verlust* und *Genauigkeit* habe ich hier eher als zusÃ¤tzliche Indikatoren gesehen, um etwas diverser auf die NÃ¼tzlichkeit meiner splinebasierten Aktivierung zu schlieÃŸen.

Datasets:

1. FashionMnist

2. Cifar10

3. TinyImagenet-200

---

## ğŸ› ï¸ Setup

Projekt Setup:

```sh
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

FÃ¼r CUDA 12.6 UnterstÃ¼tzung:

``` sh
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
```

---

TinyImagenet-200 herunterladen von [kaggle](https://www.kaggle.com/datasets/nikhilshingadiya/tinyimagenet200) oder mit:

``` sh
wget http://cs231n.stanford.edu/tiny-imagenet-200.zip
```

Danach **entpackt** im Projektordner unter `data/` ablegen.

> Alle anderen Datasets werden automatisch mit ausfÃ¼hren des Codes heruntergeladen und gespeichert.

---

## ğŸš€ Einzelnes Experiment starten

``` sh
python experiments/run_experiment.py --config experiments/configs/spline_cifar10.yaml
```
- Logs: `logs/<experiment_name>/`
- Metriken: `metrics.csv`
- Trainings Log: `training.log`

---

## ğŸ“Š Alle vorhandenen csv-Logs plotten

``` sh
python results/plots/plot_all.py
```
- Durchsucht alle vorhandenen log-Unterverzeichnisse nach `metrics.csv` Dateien
- Plottet Gradient Heatmaps, sowie Loss und Accuracies entsprechend
- Plots werden unter `results/plots/gradient_heatmaps/` und `results/plots/loss_acc/` entsprechend gespeichert

---

## ğŸ” Alle Experimente automatisch ausfÃ¼hren

``` sh
python run_all_experiments.py
```
- LÃ¤uft alle `.yaml` in `experiments/configs/` durch
- FÃ¼hrt Training, CSV-Logging und Plotting entsprechend durch

---

## ğŸ“‚ Projektstruktur

``` sh
spline-vgp-project/
â”œâ”€â”€ data/
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ configs/            # YAML-Experimente
â”‚   â””â”€â”€ run_experiment.py   # Einzellauf
â”œâ”€â”€ logs/
â”œâ”€â”€ models/  
â”‚   â”œâ”€â”€ activations.py      # Stellt Aktivierungen bereit
â”‚   â”œâ”€â”€ feedforward.py      # FFN-Implementierung
â”‚   â””â”€â”€ sigmoid_spline_activation.py  # Eigene optimierte Sigmoid Implementierung mit Hilfe von Splines
â”œâ”€â”€ results/
â”‚   â””â”€â”€ plots/              
â”‚       â”œâ”€â”€ gradient_heatmaps         # Heatmaps von GradientenverlÃ¤ufen (norm und mean_abs)
â”‚       â””â”€â”€ loss_acc                  # Graphen fÃ¼r Loss- und AccuracyverlÃ¤ufe (train und val)
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ trainer.py          # Train- und Validation-Implementation
â”‚   â””â”€â”€ utils.py            # Utils wie dataloader-Bereitstellung, seed-setting oder Gewichtsinitialisierungs
â”œâ”€â”€ run_all_experiments.py  # Automatisierter Durchlauf aller Experimente + Plotting
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```
